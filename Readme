# Initial setup

1. Download vllm and axolotl to the root of this project:

```bash
    git clone https://github.com/OpenAccess-AI-Collective/axolotl.git
    git clone https://github.com/vllm-project/vllm.git
```

2. Manually change the number of iterations inside axolotl/examples/openllama-3b/lora.yml. Add:
```yml
    max_steps: 100
```
If you don't, you will enter a 4 hour finetuning loop.

3. Docker build:

```
    sudo docker build -t --no-cache benchmarks:latest .
```